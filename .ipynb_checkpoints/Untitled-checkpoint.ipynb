{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1973b1a-ccef-4f23-bd2e-8846f442dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hann, hamming, butter, lfilter, freqz, resample\n",
    "import scipy.io.wavfile as wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db5ea40-b70d-46a5-baa0-9c867f9ca2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ste(frame):\n",
    "    energy = sum([sample**2 for sample in frame])\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23220eba-f9f2-408f-b0dd-9c894c9e99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_based_speech_silence_discrimination(y, fs):\n",
    "    frame_size = 20\n",
    "    N = len(y)\n",
    "#     time mỗi frame\n",
    "    fr_time = 0.025 \n",
    "#     số mẫu trên một frame\n",
    "    fr_len = round(fr_time * fs);\n",
    "#     tổng số frame của tín hiệu\n",
    "    fr_num = round(N/fr_len);\n",
    "#     \n",
    "    ste = np.array([calculate_ste(y[i:i+frame_length]) for i in range(0, N-fr_len+1)])\n",
    "    return ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b82352-926d-43aa-81eb-84a75dc255e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 [145 206 243 ...  88  70  98]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'audio_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fs,signal\u001b[38;5;241m=\u001b[39mwav\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphone_F1.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(fs,signal)\n\u001b[1;32m----> 3\u001b[0m \u001b[43menergy_based_speech_silence_discrimination\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [10], line 11\u001b[0m, in \u001b[0;36menergy_based_speech_silence_discrimination\u001b[1;34m(y, fs)\u001b[0m\n\u001b[0;32m      9\u001b[0m     fr_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(N\u001b[38;5;241m/\u001b[39mfr_len);\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#     \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     ste \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([calculate_ste(audio_signal[i:i\u001b[38;5;241m+\u001b[39mframe_length]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, N\u001b[38;5;241m-\u001b[39mfr_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ste\n",
      "Cell \u001b[1;32mIn [10], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     fr_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(N\u001b[38;5;241m/\u001b[39mfr_len);\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#     \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     ste \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([calculate_ste(\u001b[43maudio_signal\u001b[49m[i:i\u001b[38;5;241m+\u001b[39mframe_length]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, N\u001b[38;5;241m-\u001b[39mfr_len\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ste\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_signal' is not defined"
     ]
    }
   ],
   "source": [
    "fs,signal=wav.read('phone_F1.wav')\n",
    "print(fs,signal)\n",
    "energy_based_speech_silence_discrimination(signal,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2b64d-bc68-4dde-9568-eaa3abdb6d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
